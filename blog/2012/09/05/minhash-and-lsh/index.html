
<!DOCTYPE html>
<!--[if IEMobile 7 ]><html class="no-js iem7"><![endif]-->
<!--[if lt IE 9]><html class="no-js lte-ie8"><![endif]-->
<!--[if (gt IE 8)|(gt IEMobile 7)|!(IEMobile)|!(IE)]><!--><html class="no-js" lang="en"><!--<![endif]-->
<head>
  <meta charset="utf-8">
  <title>Minhash and LSH - yangpeng's Blog</title>
  <meta name="author" content="yp">

  
  <meta name="description" content="本文主要参考Mining of Massive Datasets中第三章相关内容。 Jaccard Similarity 在推荐系统经常要做相似度计算，其中比较简单的一种是Jaccard Similarity。Jaccard Similarity描述如下：
设A,B为两个特征向量， &hellip;">
  

  <!-- http://t.co/dKP3o1e -->
  <meta name="HandheldFriendly" content="True">
  <meta name="MobileOptimized" content="320">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  
  <link rel="canonical" href="http://yangpengg.github.com/blog/2012/09/05/minhash-and-lsh/">
  <link href="/favicon.png" rel="icon">
  <link href="/stylesheets/screen.css" media="screen, projection" rel="stylesheet" type="text/css">
  <script src="/javascripts/modernizr-2.0.js"></script>
  <script src="/javascripts/ender.js"></script>
  <script src="/javascripts/octopress.js" type="text/javascript"></script>
  <link href="/atom.xml" rel="alternate" title="yangpeng's Blog" type="application/atom+xml">
  <!--Fonts from Google"s Web font directory at http://google.com/webfonts -->
<link href="http://fonts.googleapis.com/css?family=PT+Serif:regular,italic,bold,bolditalic" rel="stylesheet" type="text/css">
<link href="http://fonts.googleapis.com/css?family=PT+Sans:regular,italic,bold,bolditalic" rel="stylesheet" type="text/css">

  

</head>

<body   >
  <header role="banner"><hgroup>
  <h1><a href="/">yangpeng's Blog</a></h1>
  
</hgroup>

</header>
  <nav role="navigation"><ul class="subscription" data-subscription="rss">
  <li><a href="/atom.xml" rel="subscribe-rss" title="subscribe via RSS">RSS</a></li>
  
</ul>
  
<form action="http://google.com/search" method="get">
  <fieldset role="search">
    <input type="hidden" name="q" value="site:yangpengg.github.com" />
    <input class="search" type="text" name="q" results="0" placeholder="Search"/>
  </fieldset>
</form>
  
<ul class="main-navigation">
  <li><a href="/">Blog</a></li>
  <li><a href="/blog/archives">Archives</a></li>
</ul>

</nav>
  <div id="main">
    <div id="content">
      <div>
<article class="hentry" role="article">
  
  <header>
    
      <h1 class="entry-title">Minhash and LSH</h1>
    
    
      <p class="meta">
        








  


<time datetime="2012-09-05T09:05:00+08:00" pubdate data-updated="true">Sep 5<span>th</span>, 2012</time>
        
      </p>
    
  </header>


<div class="entry-content"><p>本文主要参考<a href="http://i.stanford.edu/~ullman/mmds.html">Mining of Massive Datasets</a>中第三章相关内容。</p>

<h1 id="jaccard-similarity">Jaccard Similarity</h1>

<p>在推荐系统经常要做相似度计算，其中比较简单的一种是<a href="http://en.wikipedia.org/wiki/Jaccard_index">Jaccard Similarity</a>。Jaccard Similarity描述如下：<br />
设A,B为两个特征向量，比如为两个user投过票的电影，则  </p>

<script type="math/tex; mode=display">
J(A, B) = \frac{|A \cap B|}{|A \cup B|}
</script>

<p>J(A,B)的值介于0-1之间，数值越大，相似度越高。</p>

<p>Jaccard相似度计算很简单，但是当特征向量维数很高的时候(比如文档的特征向量经常会上万维)，这个计算也会很耗时，这时通用的方法是降维，Minhash也可以算作针对Jaccard相似度的降维方法。</p>

<h1 id="minhash">Minhash</h1>

<p>Minhash思想是用一个维度比较小的<em>signatures</em>代替原来维度很大的特征向量，而且可以通过计算这个signatures向量Jaccard相似度去估计原来特征向量的Jaccard相似度。</p>

<h2 id="section">特征向量的矩阵表示</h2>

<p>如S1 = {a, d}, S2 = {c}, S3 = {b, d, e}, S4 = {a, c, d}，则表示为矩阵：</p>

<p><img src="/images/blogpng/matrix-representation.png" alt="Matrix Representation" /></p>

<p>以电商为例，这个矩阵可以解释为：用户S1购买过a,d两个商品，S2购买过c，S3购买过b,d,e，…</p>

<h2 id="minhash-1">Minhash计算原理</h2>

<p>为了推荐物品给S1，思路可以是计算出和S1相似的用户，查看这个(些)用户的购买记录，推荐其中S1没有购买过的商品。可以使用Jaccard相似度计算S1的相似用户，但是现在用户的特征向量是5维的，是不是可以使用更少的维度就可以得到Jaccard相似度。</p>

<p>取Element的一个全排列，以beadc为例，这个排列定义了一个hash函数，这个函数的矩阵可以表示：</p>

<p><img src="/images/blogpng/permutation.png" alt="a permutation" /></p>

<p>根据这个hash函数，每个特征向量的minhash值定义为：第一个value不为0的Element的值。</p>

<p>从矩阵中可以的得到：<br />
h(S1) = a, h(S2) = c, h(S3) = b, h(S4) = a</p>

<p>可以取另一个Element的不同的全排列，再进行一次以上的步骤，可以得到一组不同的minhash值。将所有的minhash值组合成矩阵，则新生成的矩阵可以作为新的特征向量。如果只取两个排列的话，则原来的5维特征向量降到了2维。</p>

<h2 id="minhash-2">计算Minhash</h2>

<p>实际应用中，如果特征维度很高的话，产生一次全排列是很费时的，所以通常并不会通过产生全排列计算minhash值。</p>

<p>如果特征向量为k维，则可以取n个hash函数，将0,1,…,k-1重新映射到0,1,…,k-1。类比于全排列，这些hash函数的意义相当于将第r维的特征放到了h(r)维，相当于产生了n个全排列。当然hash函数不可避免会有冲突，但是只要k足够大(如果不够大的话，就不需要minhash了)，而冲突不太多的时候，这个影响可以忽略。</p>

<p>如果以h1,h2,…,hn表示n个随机hash函数，r表示原矩阵的行数，SIG(i, c)表示为新生成矩阵第i个hash函数(也就是第i行)，第c列的元素。首先设所有SIG中的元素为MAXINT，然后对每一行r作如想处理：</p>

<p><img src="/images/blogpng/algo-minhash.png" alt="algo minhash" /></p>

<p>Minhash的python实现：</p>

<div class="bogus-wrapper"><notextile><figure class="code"><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
<span class="line-number">7</span>
<span class="line-number">8</span>
<span class="line-number">9</span>
<span class="line-number">10</span>
<span class="line-number">11</span>
<span class="line-number">12</span>
<span class="line-number">13</span>
<span class="line-number">14</span>
<span class="line-number">15</span>
<span class="line-number">16</span>
<span class="line-number">17</span>
<span class="line-number">18</span>
<span class="line-number">19</span>
<span class="line-number">20</span>
<span class="line-number">21</span>
<span class="line-number">22</span>
<span class="line-number">23</span>
<span class="line-number">24</span>
<span class="line-number">25</span>
<span class="line-number">26</span>
<span class="line-number">27</span>
<span class="line-number">28</span>
<span class="line-number">29</span>
<span class="line-number">30</span>
<span class="line-number">31</span>
<span class="line-number">32</span>
<span class="line-number">33</span>
<span class="line-number">34</span>
<span class="line-number">35</span>
<span class="line-number">36</span>
<span class="line-number">37</span>
<span class="line-number">38</span>
<span class="line-number">39</span>
<span class="line-number">40</span>
<span class="line-number">41</span>
<span class="line-number">42</span>
<span class="line-number">43</span>
<span class="line-number">44</span>
<span class="line-number">45</span>
<span class="line-number">46</span>
<span class="line-number">47</span>
<span class="line-number">48</span>
<span class="line-number">49</span>
<span class="line-number">50</span>
<span class="line-number">51</span>
<span class="line-number">52</span>
<span class="line-number">53</span>
<span class="line-number">54</span>
<span class="line-number">55</span>
</pre></td><td class="code"><pre><code class=""><span class="line">#!/usr/bin/env python
</span><span class="line"># -*- coding: utf-8 -*-
</span><span class="line">
</span><span class="line">
</span><span class="line">def minhash(data, hashfuncs):
</span><span class="line">    '''
</span><span class="line">        see mining-of-massive-datasets.pdf ch3 minhash for detail
</span><span class="line">    '''
</span><span class="line">
</span><span class="line">    # DEBUG = True
</span><span class="line">    DEBUG = False
</span><span class="line">
</span><span class="line">    rows, cols, sigrows = len(data), len(data[0]), len(hashfuncs)
</span><span class="line">
</span><span class="line">    # fucking the shadow copy
</span><span class="line">    # sigmatrix = [[1000000] * cols] * sigrows
</span><span class="line">    sigmatrix = []
</span><span class="line">    for i in range(sigrows):
</span><span class="line">        sigmatrix.append([10000000] * cols)
</span><span class="line">
</span><span class="line">    for r in range(rows):
</span><span class="line">        hashvalue = map(lambda x: x(r), hashfuncs)
</span><span class="line">        if DEBUG: print hashvalue
</span><span class="line">        for c in range(cols):
</span><span class="line">            if DEBUG: print '-' * 2, r, c
</span><span class="line">            if data[r][c] == 0:
</span><span class="line">                continue
</span><span class="line">            for i in range(sigrows):
</span><span class="line">                if DEBUG: print '-' * 4, i, sigmatrix[i][c], hashvalue[i]
</span><span class="line">                if sigmatrix[i][c] &gt; hashvalue[i]:
</span><span class="line">                    sigmatrix[i][c] = hashvalue[i]
</span><span class="line">                if DEBUG: print '-' * 4, sigmatrix
</span><span class="line">
</span><span class="line">        if DEBUG:
</span><span class="line">            for xxxxxxx in sigmatrix:
</span><span class="line">                print xxxxxxx
</span><span class="line">            print '=' * 30
</span><span class="line">
</span><span class="line">    return sigmatrix
</span><span class="line">
</span><span class="line">
</span><span class="line">if __name__ == '__main__':
</span><span class="line">    def hash1(x):
</span><span class="line">        return (x + 1) % 5
</span><span class="line">
</span><span class="line">    def hash2(x):
</span><span class="line">        return (3 * x + 1) % 5
</span><span class="line">
</span><span class="line">    data = [[1, 0, 0, 1],
</span><span class="line">            [0, 0, 1, 0],
</span><span class="line">            [0, 1, 0, 1],
</span><span class="line">            [1, 0, 1, 1],
</span><span class="line">            [0, 0, 1, 0]]
</span><span class="line">
</span><span class="line">    print minhash(data, [hash1, hash2])</span></code></pre></td></tr></table></div></figure></notextile></div>

<h1 id="locality-sensitive-hashing">Locality-Sensitive Hashing</h1>

<p>在推荐系统中，通常需要的是与S1 n个最相似的，而不是所有的。<a href="http://en.wikipedia.org/wiki/Locality_sensitive_hashing">Locality-Sensitive Hashing</a>的提出就是为了过滤明显不相似的，以此来减少计算。</p>

<p>假设向量的维度为n，将n维分为b份，称为bands，每份为n/b维。同时存在b个hash函数，每个bands对应一个hash函数，每个hash函数接受n/b个参数，产生一个数值，把相同数值的元素分为一组。</p>

<p>对每个binds中的n/b维特征向量进行hash计算，比如对于{S1, S2, S3, S4}，3个binds而言，第一个binds可能产生的数据为{S1, S2}, {S3}, {S4}，第二个binds为{S1}, {S2, S4}, {S3}，第三个binds为{S1, S3}, {S2, S4}。则为了计算得到和S1最相似的n个，则只需要计算J(S1, S2), J(S1, S3)，这样达到了减少了计算的目的。</p>

</div>


  <footer>
    <p class="meta">
      
  

<span class="byline author vcard">Posted by <span class="fn">yp</span></span>

      








  


<time datetime="2012-09-05T09:05:00+08:00" pubdate data-updated="true">Sep 5<span>th</span>, 2012</time>
      

<span class="categories">
  
    <a class='category' href='/blog/categories/algorithm/'>Algorithm</a>, <a class='category' href='/blog/categories/recommender-system/'>Recommender System</a>
  
</span>


    </p>
    
      <div class="sharing">
  
  <a href="http://twitter.com/share" class="twitter-share-button" data-url="http://yangpengg.github.com/blog/2012/09/05/minhash-and-lsh/" data-via="yangpengg" data-counturl="http://yangpengg.github.com/blog/2012/09/05/minhash-and-lsh/" >Tweet</a>
  
  
  
</div>

    
    <p class="meta">
      
        <a class="basic-alignment left" href="/blog/2012/08/21/octopress-setup/" title="Previous Post: Octopress Setup">&laquo; Octopress Setup</a>
      
      
        <a class="basic-alignment right" href="/blog/2012/11/02/view-transition-follow-finger/" title="Next Post: View Transition follow Finger">View Transition follow Finger &raquo;</a>
      
    </p>
  </footer>
</article>

</div>

<aside class="sidebar">
  
    <section>
  <h1>Yang Peng</h1>
  
  <p>I like machine learning, recommender system and nlp.</p>

  <p>Email: hermitinhistory[at]gmail.com<br/>
  Twitter: <a href="https://twitter.com/#!/yangpengg">@yangpengg</a><br/>
</section>
<section>
  <h1>Recent Posts</h1>
  <ul id="recent_posts">
    
      <li class="post">
        <a href="/blog/2012/12/15/mathjax-test/">MathJax Test</a>
      </li>
    
      <li class="post">
        <a href="/blog/2012/12/13/decode-and-encode-in-python/">Decode and Encode in Python</a>
      </li>
    
      <li class="post">
        <a href="/blog/2012/11/02/view-transition-follow-finger/">View Transition follow Finger</a>
      </li>
    
      <li class="post">
        <a href="/blog/2012/09/05/minhash-and-lsh/">Minhash and LSH</a>
      </li>
    
      <li class="post">
        <a href="/blog/2012/08/21/octopress-setup/">Octopress Setup</a>
      </li>
    
  </ul>
</section>

<section>
  <h1>Latest Tweets</h1>
  <ul id="tweets">
    <li class="loading">Status updating...</li>
  </ul>
  <script type="text/javascript">
    $.domReady(function(){
      getTwitterFeed("yangpengg", 4, false);
    });
  </script>
  <script src="/javascripts/twitter.js" type="text/javascript"> </script>
  
    <a href="http://twitter.com/yangpengg" class="twitter-follow-button" data-show-count="true">Follow @yangpengg</a>
  
</section>


  
</aside>


    </div>
  </div>
  <footer role="contentinfo"><p>
  Copyright &copy; 2012 - yp -
  <span class="credit">Powered by <a href="http://octopress.org">Octopress</a></span>
</p>

</footer>
  







  <script type="text/javascript">
    (function(){
      var twitterWidgets = document.createElement('script');
      twitterWidgets.type = 'text/javascript';
      twitterWidgets.async = true;
      twitterWidgets.src = 'http://platform.twitter.com/widgets.js';
      document.getElementsByTagName('head')[0].appendChild(twitterWidgets);
    })();
  </script>





</body>
</html>


<!-- mathjax config similar to math.stackexchange -->
<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  jax: ["input/TeX", "output/HTML-CSS"],
  tex2jax: {
    inlineMath: [ ['$', '$'] ],
    displayMath: [ ['$$', '$$']],
    processEscapes: true,
    skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
  },
  messageStyle: "none",
  "HTML-CSS": { preferredFont: "TeX", availableFonts: ["STIX","TeX"] }
});
</script>
<script src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS_HTML" type="text/javascript"></script>
