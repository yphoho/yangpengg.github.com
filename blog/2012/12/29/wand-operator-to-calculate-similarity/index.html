
<!DOCTYPE html>
<!--[if IEMobile 7 ]><html class="no-js iem7"><![endif]-->
<!--[if lt IE 9]><html class="no-js lte-ie8"><![endif]-->
<!--[if (gt IE 8)|(gt IEMobile 7)|!(IEMobile)|!(IE)]><!--><html class="no-js" lang="en"><!--<![endif]-->
<head>
  <meta charset="utf-8">
  <title>WAND Operator to Calculate Similarity - yangpeng's Blog</title>
  <meta name="author" content="yp">

  
  <meta name="description" content="本文主要内容来自论文 Efficient Query Evaluation using a Two-Level Retrieval Process 。论文全文可以在这里下载。 WAND全称Weak AND或者Weighted AND，主要用于计算文档之间的相似度。 在进入正题之前， &hellip;">
  

  <!-- http://t.co/dKP3o1e -->
  <meta name="HandheldFriendly" content="True">
  <meta name="MobileOptimized" content="320">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  
  <link rel="canonical" href="http://yangpengg.github.com/blog/2012/12/29/wand-operator-to-calculate-similarity/">
  <link href="/favicon.png" rel="icon">
  <link href="/stylesheets/screen.css" media="screen, projection" rel="stylesheet" type="text/css">
  <script src="/javascripts/modernizr-2.0.js"></script>
  <script src="/javascripts/ender.js"></script>
  <script src="/javascripts/octopress.js" type="text/javascript"></script>
  <link href="/atom.xml" rel="alternate" title="yangpeng's Blog" type="application/atom+xml">
  <!--Fonts from Google"s Web font directory at http://google.com/webfonts -->
<link href="http://fonts.googleapis.com/css?family=PT+Serif:regular,italic,bold,bolditalic" rel="stylesheet" type="text/css">
<link href="http://fonts.googleapis.com/css?family=PT+Sans:regular,italic,bold,bolditalic" rel="stylesheet" type="text/css">

  
  <script type="text/javascript">
    var _gaq = _gaq || [];
    _gaq.push(['_setAccount', 'UA-37283517-1']);
    _gaq.push(['_trackPageview']);

    (function() {
      var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
      ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
      var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
    })();
  </script>


</head>

<body   >
  <header role="banner"><hgroup>
  <h1><a href="/">yangpeng's Blog</a></h1>
  
</hgroup>

</header>
  <nav role="navigation"><ul class="subscription" data-subscription="rss">
  <li><a href="/atom.xml" rel="subscribe-rss" title="subscribe via RSS">RSS</a></li>
  
</ul>
  
<form action="http://google.com/search" method="get">
  <fieldset role="search">
    <input type="hidden" name="q" value="site:yangpengg.github.com" />
    <input class="search" type="text" name="q" results="0" placeholder="Search"/>
  </fieldset>
</form>
  
<ul class="main-navigation">
  <li><a href="/">Blog</a></li>
  <li><a href="/blog/archives">Archives</a></li>
</ul>

</nav>
  <div id="main">
    <div id="content">
      <div>
<article class="hentry" role="article">
  
  <header>
    
      <h1 class="entry-title">WAND Operator to Calculate Similarity</h1>
    
    
      <p class="meta">
        








  


<time datetime="2012-12-29T10:44:00+08:00" pubdate data-updated="true">Dec 29<span>th</span>, 2012</time>
        
      </p>
    
  </header>


<div class="entry-content"><p>本文主要内容来自论文 <em>Efficient Query Evaluation using a Two-Level Retrieval Process</em> 。论文全文可以在<a href="http://www.cis.upenn.edu/~jstoy/cis650/papers/WAND.pdf">这里</a>下载。</p>

<p>WAND全称Weak AND或者Weighted AND，主要用于计算文档之间的相似度。</p>

<p>在进入正题之前，先给出一条微博中提到的<a href="http://weibo.com/1751942113/zbGSlsXFw">性能对比</a>，不保证数据的权威性，仅仅提供一个大致参考。</p>

<h1 id="ir">IR中与文档相似度相关的几个概念</h1>

<h2 id="httpenwikipediaorgwikiinvertedindex"><a href="http://en.wikipedia.org/wiki/Inverted_index">倒排索引</a></h2>
<p>在<a href="http://en.wikipedia.org/wiki/Vector_space_model">向量空间模型</a>中一篇文档(document)通常会表示为词(term)的向量，比如这样的三个文档:</p>

<ul>
  <li>$d_1$: I love you.</li>
  <li>$d_2$: I hate you.</li>
  <li>$d_3$: I miss you.</li>
</ul>

<p>表示为： $d_1$ = [1, 1, 0, 0, 1], $d_2$ = [1, 0, 1, 0, 1], $d_3$ = [1, 0, 0, 1, 1]。 向量位置依次表示[I, love, hate, miss, you]，其中1表示在文档中出现，0表示没有出现。</p>

<p>上面是文档表示，其相应的倒排索引可以表示为：</p>

<ul>
  <li>I: [1, 2, 3]</li>
  <li>love: [1]</li>
  <li>hate: [2]</li>
  <li>miss: [3]</li>
  <li>you: [1, 2, 3]</li>
</ul>

<p>当然在索引中除了可以出现文档信息，还可以添加其它信息，比如这个term在此文档中出现的次数。文档会有一个唯一的id号，称为DID，在倒排索引中文档通常是按照DID的增序排列。</p>

<h2 id="posting--posting-list">posting 和 posting list</h2>

<p>在倒排索引中以冒号作为分割可以分为两部分，第一部分称为字典(dictionary)，第二部分称为posting(也称为posting list)。所有的posting合在一起称为postings(或者posting lists)。</p>

<h2 id="tf-idf">tf-idf</h2>

<p>这个概念有点复杂，可以直接看<a href="http://en.wikipedia.org/wiki/Tf%E2%80%93idf">wikipedia</a>和吴军博士数学之美中的<a href="http://googlechinablog.blogspot.com/2006/06/blog-post_3066.html">相关解释</a>。</p>

<h1 id="section">两段评估</h1>

<p>通常完全评估两篇文档的相似度计算量很大，为了减少计算，可以在完全评估之前引入另一个比较廉价的计算(本文称之为预计算)，并且设置一个threshold，只有当这个廉价的计算结果大于threshold的时候才进行费时的完全计算。</p>

<p>WAND算法正是采用了这种想法，而且WAND算法在预计算时也进行了优化，使得其在性能上有很大的提升。</p>

<h2 id="wand">WAND定义</h2>

<script type="math/tex; mode=display">
WAND(X_1, w_1, X_2, w_2, \cdots, X_n, w_n, \theta) = \sum_{i=1}^nx_iw_i \geq \theta
</script>

<p>其中$X_1$为布尔值，$w_i$为权重，$x_i$称为<a href="http://en.wikipedia.org/wiki/Indicator_function">indicator function</a>，定义为</p>

<script type="math/tex; mode=display">
x_i = \{_{0, \ otherwise}^{1, \ if \ X_i \ is \ true}
</script>

<p>整个WAND操作的结果也是一个布尔值。</p>

<p>有趣的是，我们可以用WAND操作定义AND和OR：</p>

<script type="math/tex; mode=display">
AND(X_1, X_2, \cdots, X_k) \equiv WAND(X_1, 1, X_2, 1, \cdots, X_k, 1, k) \\
OR(X_1, X_2, \cdots, X_k) \equiv WAND(X_1, 1, X_2, 1, \cdots, X_k, 1, 1)
</script>

<h2 id="section-1">评估函数</h2>

<p>这里定义的评估函数是一个累加模型(additive scoring model)，也就是说，两个文档的相似程度是由所有的词作出的贡献的和：</p>

<script type="math/tex; mode=display">
Score(d_a, d_b) = \sum_{t\in d_a\cap d_b}\alpha_t w(t, d_b)
</script>

<p>这里我们固定$d_a$，而把$d_b$作为变量，也就是求所有的文档与$d_a$的相似度。</p>

<p>同时注意到一点，这个公式是不对称的，也就是说$d_a, d_b$的相似度，与
$d_b, d_a$的相似度并不相同。</p>

<p>对于以上的Score函数，论文大致解释如下：</p>

<blockquote>
  <p>For example, for the tf × idf scoring model used by many IR systems, $\alpha_t$ is a function of the number of occurrences of $t$ in the $d_a$, multiplied by the inverse document frequency (idf) of $t$ in the index and $w(t,d_b)$ is a function of the term frequency (tf) of $t$ in $d_b$, divided by the document length $|d_b|$.</p>
</blockquote>

<p>从wikipedia中看到关于tf的定义是不确定的，从上文推断，这里的tf应该指的是raw frequency，也就是一个词t在文档d的出现的次数(tf(t,d))。这里的index应该指所有的文档(corpus)。</p>

<p>如果这样理解，上边一段话用数学公式表示为：</p>

<script type="math/tex; mode=display">
\alpha_t = tf(t, d_a) * idf(t) \\
w(t,d_b) = \frac{tf(t, d_b)}{\|d_b\|}
</script>

<p>上面提到公式不对称，主要就是差在一个文档长度上，如果求$Score(d_a, d_b)$则分母是$|d_b|$，如果求$Score(d_b, d_a)$分母为$|d_a|$。如果定义Score为再除以一个$|d_a|$使得公式对称，这样也没有问题，但是通常情况下我们需要的是与$d_a$最相似的n个文档，相似度计算中是否除以$|d_a|$并不会影响相似文档的排名。</p>

<h2 id="section-2">预计算公式</h2>

<p>对于每个词，可以定义一个上界(upper bound)：</p>

<script type="math/tex; mode=display">
UB_t \geq \alpha_t max(w(t, d_1), w(t, d_2), \cdots)
</script>

<p>由上式以及之前的累加模型假设，文档相似度的上界为：</p>

<script type="math/tex; mode=display">
UB(d_a, d_b) = \sum_{t \in d_a \cap d_b}UB_t
</script>

<p>明显可以得到以下结论：</p>

<script type="math/tex; mode=display">
UB(d_a, d_b) \geq Score(d_a, d_b)
</script>

<p>有了以上的结论，再结合之前定义的WAND操作，可以定义一个计算复杂度比较低的公式：</p>

<script type="math/tex; mode=display">
WAND(X_1, UB_1, X_2, UB_2, \cdots, X_n, UB_n, \theta)
</script>

<p>其中$X_i$是indicator变量，$t_i$为$d_a$中出现的词，当$t_i$出现在$d_b$中时$X_i = 1$，否则$X_i = 0$。</p>

<h2 id="section-3">相似度计算</h2>

<p>定义上边的公式之后，计算两个文档$d_a, d_b$的相似度成为以下两个过程：</p>

<ol>
  <li>取$d_a$所有词$t_i$以及相应的$UB_i$，当$t_i$出现在$d_b$时，取$X_i = 1$，否则取$X_i = 0$，将$X_i, UB_i$代入以上公式求解；</li>
  <li>当1中求解结果为true时，计算$Score(d_a, d_b)$，否则不做任何事情；</li>
</ol>

<h2 id="top-n">求解top-n相似文档</h2>

<p>如果按照之前的提到方法计算$d_a$的n个最相似文档，就要取出所有的文档，每个文档作预计算，比较threshold，然后决定是否在top-n之列。这样计算当然可行，但是还是可以优化的。优化的出发点就是尽量减少预计算，论文中提到的算法如下：</p>

<ol>
  <li>提取出$d_a$中所有的词，以及这些词的倒排索引；</li>
  <li>初始化curDoc=0；</li>
  <li>初始化posting数组，使得posting[t]为词t倒排索引中第一个文档；</li>
</ol>

<p>可以定义一个next函数，用于查找下一个进行完全计算的文档，论文中对next描述如下：</p>

<div class="bogus-wrapper"><notextile><figure class="code"><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
<span class="line-number">7</span>
<span class="line-number">8</span>
<span class="line-number">9</span>
<span class="line-number">10</span>
<span class="line-number">11</span>
<span class="line-number">12</span>
<span class="line-number">13</span>
<span class="line-number">14</span>
<span class="line-number">15</span>
<span class="line-number">16</span>
<span class="line-number">17</span>
<span class="line-number">18</span>
<span class="line-number">19</span>
<span class="line-number">20</span>
<span class="line-number">21</span>
<span class="line-number">22</span>
<span class="line-number">23</span>
</pre></td><td class="code"><pre><code class=""><span class="line">Function next(θ)
</span><span class="line">  repeat
</span><span class="line">    /* Sort the terms in non decreasing order of DID */
</span><span class="line">    sort(terms, posting)
</span><span class="line">    /* Find pivot term - the first one with accumulated UB ≥ θ */
</span><span class="line">    pTerm ← findPivotTerm(terms, θ)
</span><span class="line">    if (pTerm = null) return (NoMoreDocs)
</span><span class="line">    pivot ← posting[pTerm].DID
</span><span class="line">    if (pivot = lastID) return (NoMoreDocs)
</span><span class="line">    if (pivot ≤ curDoc)
</span><span class="line">      /* pivot has already been considered, advance one of the preceding terms */
</span><span class="line">      aterm ← pickTerm(terms[0..pTerm])
</span><span class="line">      posting[aterm] ← aterm.iterator.next(curDoc+1)
</span><span class="line">    else /* pivot &gt; curDoc */
</span><span class="line">      if (posting[0].DID = pivot)
</span><span class="line">        /* Success, all terms preceding pTerm belong to the pivot */
</span><span class="line">        curDoc ← pivot
</span><span class="line">        return (curDoc, posting)
</span><span class="line">      else
</span><span class="line">        /* not enough mass yet on pivot, advance one of the preceding terms */
</span><span class="line">        aterm ← pickTerm(terms[0..pTerm])
</span><span class="line">        posting[aterm] ← aterm.iterator.next(pivot)
</span><span class="line">  end repeat</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>其中用到了几个函数，解释如下：</p>

<h3 id="atermiteratornextn">aterm.iterator.next(n)</h3>

<p>这个函数返回aterm倒排索引中的DID，这个DID要满足DID &gt;= n。</p>

<h3 id="sortterms-posting">sort(terms, posting)</h3>

<p>sort是把terms按照posting当前指向的DID的非递减排序。比如$d_a$所有词的倒排索引为：</p>

<ul>
  <li>$t_0$: [1, 3, 26]</li>
  <li>$t_1$: [1, 2, 4, 10, 100]</li>
  <li>$t_2$: [2, 3, 6, 34, 56]</li>
  <li>$t_3$: [1, 4, 5, 23, 70, 200]</li>
  <li>$t_4$: [5, 14, 78]</li>
</ul>

<p>当前posting数组为：[2, 2, 0, 3, 0]</p>

<p>根据以上两条信息，可以得到：{$t_0$ : 26, $t_1$ : 4, $t_2$ : 2, $t_3$ : 23, $t_4$ : 5}</p>

<p>则排序后的结果为[$t_2$, $t_1$, $t_4$, $t_3$, $t_0$]</p>

<h3 id="findpivottermterms-">findPivotTerm(terms, θ)</h3>

<p>按照之前得到的排序，返回第一个上界累加和$\geq \theta$的term。</p>

<p>引入以下数据：[$UB_0$, $UB_1$, $UB_2$, $UB_3$, $UB_4$] = [0, 1, 2, 3, 4], $\theta$ = 8</p>

<p>因为(2 + 1 + 4) = 7 &lt; 8 而 (2 + 1 + 4 + 3) = 10 &gt; 8，所以此函数返回$t_3$</p>

<h3 id="picktermterms0pterm">pickTerm(terms[0..pTerm])</h3>

<p>在0到pTerm(不包含pTerm)中选择一个term。</p>

<p>还是用之前的数据，则是在[$t_2$, $t_1$, $t_4$](没有$t_3$)中选择一个term返回。</p>

<p>关于选择策略，当然是以可以跳过最多的文档为指导，论文中选择了idf最大的term。</p>

<p>解释了以上几个函数之后，理解上边的伪码应该没有问题。至于要理解为什么这样不会错过相似度大的文档，就需要自己动一翻脑子。可以参考论文中的解释，不过说起来比较啰嗦，这里就不证明了。</p>

<p>最后要提到的一点是，在sort函数中是没有必要完全排序的，因为每一次循环都只是改变了posting中的一条数据，只要把这个数据排好序就可以了。</p>
</div>


  <footer>
    <p class="meta">
      
  

<span class="byline author vcard">Posted by <span class="fn">yp</span></span>

      








  


<time datetime="2012-12-29T10:44:00+08:00" pubdate data-updated="true">Dec 29<span>th</span>, 2012</time>
      

<span class="categories">
  
    <a class='category' href='/blog/categories/algorithm/'>Algorithm</a>, <a class='category' href='/blog/categories/information-retrieval/'>Information Retrieval</a>
  
</span>


    </p>
    
      <div class="sharing">
  
  <a href="http://twitter.com/share" class="twitter-share-button" data-url="http://yangpengg.github.com/blog/2012/12/29/wand-operator-to-calculate-similarity/" data-via="yangpengg" data-counturl="http://yangpengg.github.com/blog/2012/12/29/wand-operator-to-calculate-similarity/" >Tweet</a>
  
  
  
</div>

    
    <p class="meta">
      
        <a class="basic-alignment left" href="/blog/2012/12/16/linear-regression-and-the-theory/" title="Previous Post: Linear Regression and the Theory">&laquo; Linear Regression and the Theory</a>
      
      
        <a class="basic-alignment right" href="/blog/2013/01/13/life-is-short/" title="Next Post: Life is short">Life is short &raquo;</a>
      
    </p>
  </footer>
</article>

</div>

<aside class="sidebar">
  
    <section>
  <h1>Yang Peng</h1>

  <p>I like machine learning, recommender system and nlp.</p>

  <p>Email: hermitinhistory[at]gmail.com<br/>
  Twitter: <a href="https://twitter.com/#!/yangpengg">@yangpengg</a><br/>
  Weibo: <a href="http://weibo.com/yangpengg">@yanggpeng</a><br/>
</section>
<section>
  <h1>Recent Posts</h1>
  <ul id="recent_posts">
    
      <li class="post">
        <a href="/blog/2013/10/13/connect-to-lego-ev3-under-mac-os-x-with-bluetooth/">Connect to LEGO EV3 under Mac OS X with Bluetooth</a>
      </li>
    
      <li class="post">
        <a href="/blog/2013/07/20/what-you-think-is-wrong/">What You Think is Wrong</a>
      </li>
    
      <li class="post">
        <a href="/blog/2013/05/25/poisson-distribution/">Poisson Distribution</a>
      </li>
    
      <li class="post">
        <a href="/blog/2013/01/13/life-is-short/">Life is short</a>
      </li>
    
      <li class="post">
        <a href="/blog/2012/12/29/wand-operator-to-calculate-similarity/">WAND Operator to Calculate Similarity</a>
      </li>
    
      <li class="post">
        <a href="/blog/2012/12/16/linear-regression-and-the-theory/">Linear Regression and the Theory</a>
      </li>
    
      <li class="post">
        <a href="/blog/2012/12/15/mathjax-test/">MathJax Test</a>
      </li>
    
      <li class="post">
        <a href="/blog/2012/12/13/decode-and-encode-in-python/">Decode and Encode in Python</a>
      </li>
    
      <li class="post">
        <a href="/blog/2012/11/02/view-transition-follow-finger/">View Transition follow Finger</a>
      </li>
    
      <li class="post">
        <a href="/blog/2012/09/05/minhash-and-lsh/">Minhash and LSH</a>
      </li>
    
  </ul>
</section>

<section>
  <h1>Latest Tweets</h1>
  <ul id="tweets">
    <li class="loading">Status updating...</li>
  </ul>
  <script type="text/javascript">
    $.domReady(function(){
      getTwitterFeed("yangpengg", 4, false);
    });
  </script>
  <script src="/javascripts/twitter.js" type="text/javascript"> </script>
  
    <a href="http://twitter.com/yangpengg" class="twitter-follow-button" data-show-count="true">Follow @yangpengg</a>
  
</section>


  
</aside>


    </div>
  </div>
  <footer role="contentinfo"><p>
  Copyright &copy; 2013 - yp -
  <span class="credit">Powered by <a href="http://octopress.org">Octopress</a></span>
</p>

</footer>
  







  <script type="text/javascript">
    (function(){
      var twitterWidgets = document.createElement('script');
      twitterWidgets.type = 'text/javascript';
      twitterWidgets.async = true;
      twitterWidgets.src = 'http://platform.twitter.com/widgets.js';
      document.getElementsByTagName('head')[0].appendChild(twitterWidgets);
    })();
  </script>





</body>
</html>


<!-- mathjax config similar to math.stackexchange -->
<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  jax: ["input/TeX", "output/HTML-CSS"],
  tex2jax: {
    inlineMath: [ ['$', '$'] ],
    displayMath: [ ['$$', '$$']],
    processEscapes: true,
    skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
  },
  messageStyle: "none",
  "HTML-CSS": { preferredFont: "TeX", availableFonts: ["STIX","TeX"] }
});
</script>
<script src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS_HTML" type="text/javascript"></script>
